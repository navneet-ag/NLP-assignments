{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Navneet Agarwal\n",
    "#### 2018348"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Lower_case(WordsList):\n",
    "    LowerList=[word.lower() for word in WordsList]\n",
    "    return (LowerList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SentenceTokenize(TextFile):\n",
    "    SentenceTokens = sent_tokenize(TextFile)\n",
    "    return(SentenceTokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WordTokenize(TextFile):\n",
    "    WordTokens = word_tokenize(TextFile)\n",
    "    return(WordTokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuations(tokens):\n",
    "    table = str.maketrans('','', string.punctuation)\n",
    "    ptokens = [w.translate(table) for w in tokens]\n",
    "    return ptokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemmer(InitialWord):\n",
    "    from nltk.stem import PorterStemmer\n",
    "    pr = PorterStemmer()\n",
    "    StemmedWord = pr.stem(InitialWord)\n",
    "    return StemmedWord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to retrieve list of sentences.( Sentences in Metadata + Sentences in Main text )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences(FilePointer):\n",
    "    FilePointer.seek(0)\n",
    "    TempList=FilePointer.readlines()\n",
    "    for i in range(len(TempList)):\n",
    "        if(\"\\n\"==TempList[i]):\n",
    "            break\n",
    "    MetadataList=TempList[:i]\n",
    "    MainText=\"\"\n",
    "    for line in TempList[i+1:]:\n",
    "        MainText+=line\n",
    "    SentencesList=sent_tokenize(MainText) \n",
    "    return(MetadataList,SentencesList,MainText)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ques 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ques1():\n",
    "    print(\"\\n Please Enter the File Name :\")\n",
    "    FileName=input()\n",
    "    try:\n",
    "        #Sentences part     \n",
    "        FilePointer = codecs.open(FileName, 'r', encoding = 'utf-8', errors = 'ignore')\n",
    "        MetadataList,SentencesList,MainText=get_sentences(FilePointer)\n",
    "        print(\"Lines in Metadata: \",len(MetadataList))\n",
    "        print(\"Number of sentences in text(without metadata): \",len(SentencesList))\n",
    "\n",
    "        TokensList=WordTokenize(MainText)\n",
    "        TokensList=remove_punctuations(TokensList)\n",
    "        NumberOfWords=0\n",
    "        TempList=[]\n",
    "        for i in range(len(TokensList)):\n",
    "            if(len(TokensList[i])!=0):\n",
    "                if((re.match(\"^[A-Za-z]+$\",TokensList[i])) or (re.match(\"^[0-9]+$\",TokensList[i]))):\n",
    "                    NumberOfWords+=1\n",
    "                    TempList.append(TokensList[i])\n",
    "        TokensList=TempList\n",
    "        \n",
    "        print(\"Number of words in text(without metadata): \",NumberOfWords)\n",
    "    except:\n",
    "        print(\"Not a Valid file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ques 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ques2():\n",
    "    print(\"\\n Please Enter the File Name :\")\n",
    "    FileName=input()\n",
    "    try:\n",
    "        FilePointer = codecs.open(FileName, 'r', encoding = 'utf-8', errors = 'ignore')\n",
    "        VowelStartWords=[]\n",
    "        ConsonantsStartWords=[]\n",
    "        MetadataList,SentencesList,MainText=get_sentences(FilePointer)\n",
    "        TokensList=WordTokenize(MainText)\n",
    "        TokensList=remove_punctuations(TokensList)\n",
    "        for i in (TokensList):\n",
    "            if(re.match(\"^[aeiou][a-z]*$\",i.lower())):\n",
    "#                 print(i)\n",
    "                VowelStartWords.append(i)\n",
    "            elif(re.match(\"^[b-dfghj-np-tv-z][a-z]*$\",i.lower())!=None):\n",
    "                ConsonantsStartWords.append(i)\n",
    "#                 print(i)\n",
    "        print(\"Number of words starting with vowels :\"+ str(len(VowelStartWords)))\n",
    "        print(\"Number of words starting with consonants :\"+str(len(ConsonantsStartWords)))\n",
    "    except:\n",
    "        print(\"Some Error occured\")\n",
    "        print(\"File Name Maybe Wrong\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Ques 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ques3():\n",
    "    print(\"\\n Please Enter the File Name :\")\n",
    "    FileName=input()\n",
    "    try:\n",
    "        FilePointer = codecs.open(FileName, 'r', encoding = 'utf-8', errors = 'ignore')\n",
    "        TokensList=WordTokenize(FilePointer.read())\n",
    "        UniqueEmails=set()\n",
    "        EmailList=[]\n",
    "        for i in range(len(TokensList)):\n",
    "            if(TokensList[i]==\"@\" and i>0 and i<len(TokensList)-1):\n",
    "                TempMail=TokensList[i-1]+TokensList[i]+TokensList[i+1]\n",
    "                if(re.match(\"[A-Za-z0-9]+\",TokensList[i-1]) and (re.match(\"[A-Za-z0-9]+\",TokensList[i+1]))):\n",
    "                    EmailList.append(TempMail)\n",
    "                    UniqueEmails.add(TempMail)\n",
    "#                     print(TempMail)\n",
    "        print(\"\\n All the emails present in the document are:\\n\")\n",
    "        for i in EmailList:\n",
    "            print(i)\n",
    "\n",
    "        print(\"\\n All the unique emails present in the document are:\\n\")\n",
    "        for i in UniqueEmails:\n",
    "            print(i)\n",
    "    except:\n",
    "        print(\"Some Error occured\")\n",
    "        print(\"File Name Maybe Wrong\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ques 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ques4():\n",
    "    import copy\n",
    "    from word2number import w2n \n",
    "    print(\"\\n Please Enter the File Name :\")\n",
    "    FileName=input()\n",
    "    try:\n",
    "        FilePointer = codecs.open(FileName, 'r', encoding = 'utf-8', errors = 'ignore')    \n",
    "        print(\"\\n Please enter the word you want to search :\")\n",
    "        word=input()\n",
    "        word=word.lower()\n",
    "        NumberFlag=0\n",
    "        try: \n",
    "            InputNumber=w2n.word_to_num(word)\n",
    "            print(\"Input word represents the number :\"+ str(InputNumber) )\n",
    "            NumberFlag=1\n",
    "        except:\n",
    "            print(\"Input word does not represent a number\")\n",
    "        MetadataList,SentencesList,MainText=get_sentences(FilePointer)\n",
    "        OrignalSentenceList=copy.deepcopy(SentencesList)\n",
    "\n",
    "        for i in range(len(SentencesList)):\n",
    "            SentencesList[i]=SentencesList[i].replace(\"\\n\",\" \")\n",
    "            SentencesList[i]=SentencesList[i].replace(\"\\t\",\" \")    \n",
    "            SentencesList[i]=SentencesList[i].lower()\n",
    "            SentencesList[i]=WordTokenize(SentencesList[i])\n",
    "\n",
    "        NumberOfSentences=0\n",
    "        Answer4List=[]\n",
    "\n",
    "        for i in range(len(SentencesList)):\n",
    "            SplitSentence=remove_punctuations(SentencesList[i])\n",
    "            for index in range(len(SplitSentence)):\n",
    "                if(SplitSentence[index]!=\"\"):\n",
    "                    break\n",
    "            if(index==len(SplitSentence)):\n",
    "                continue\n",
    "            if(SplitSentence[index]==word or (NumberFlag==1 and SplitSentence[index]==str(InputNumber))):\n",
    "\n",
    "                NumberOfSentences+=1\n",
    "                Answer4List.append(OrignalSentenceList[i])\n",
    "        print(\"\\n Number of sentences starting with \"+word+ \" :\"+str(NumberOfSentences))\n",
    "        if(NumberOfSentences>0):\n",
    "            print(\" The sentence are as follows:\\n\")\n",
    "            for i in range(len(Answer4List)):\n",
    "                print(\"\\n\"+str(i+1)+\":\",end=\" \")\n",
    "                print(Answer4List[i])\n",
    "    except:\n",
    "        print(\"Some Error occured\")\n",
    "        print(\"File Name Maybe Wrong\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ques 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ques5():\n",
    "    import copy\n",
    "    from word2number import w2n \n",
    "\n",
    "    print(\"\\n Please Enter the File Name :\")\n",
    "    FileName=input()\n",
    "    try:\n",
    "        FilePointer = codecs.open(FileName, 'r', encoding = 'utf-8', errors = 'ignore')    \n",
    "        print(\"\\n Please enter the word you want to search :\")\n",
    "        word=input()\n",
    "        word=word.lower()\n",
    "        NumberFlag=0\n",
    "        try: \n",
    "            InputNumber=w2n.word_to_num(word)\n",
    "            print(\"Input word represents the number :\"+ str(InputNumber) )\n",
    "            NumberFlag=1\n",
    "        except:\n",
    "            print(\"Input word does not represent a number\")\n",
    "\n",
    "\n",
    "        MetadataList,SentencesList,MainText=get_sentences(FilePointer)\n",
    "        OrignalSentenceList=copy.deepcopy(SentencesList)\n",
    "        for i in range(len(SentencesList)):\n",
    "            SentencesList[i]=SentencesList[i].replace(\"\\n\",\" \")\n",
    "            SentencesList[i]=SentencesList[i].replace(\"\\t\",\" \")    \n",
    "            SentencesList[i]=SentencesList[i].lower()\n",
    "            SentencesList[i]=WordTokenize(SentencesList[i])\n",
    "\n",
    "        NumberOfSentences=0\n",
    "        Answer5List=[]\n",
    "        # count=0\n",
    "        for i in range(len(SentencesList)):\n",
    "            SplitSentence=remove_punctuations(SentencesList[i])\n",
    "\n",
    "            index=len(SplitSentence)-1\n",
    "            while(index>0 and SplitSentence[index]==\"\"):\n",
    "                index-=1\n",
    "            if(index<0):\n",
    "                continue\n",
    "        #     print(SplitSentence[index])\n",
    "        #     count+=1\n",
    "            if(SplitSentence[index]==word or (NumberFlag==1 and SplitSentence[index]==str(InputNumber))):\n",
    "                NumberOfSentences+=1\n",
    "                Answer5List.append(OrignalSentenceList[i])\n",
    "        # print(count,len(SentencesList))\n",
    "        print(\"\\n Number of sentences starting with \"+word+ \" :\"+str(NumberOfSentences))\n",
    "        if(NumberOfSentences>0):\n",
    "            print(\" The sentence are as follows:\\n\")\n",
    "            for i in range(len(Answer5List)):\n",
    "                print(\"\\n\"+str(i+1)+\":\",end=\" \")\n",
    "                print(Answer5List[i])\n",
    "    except:\n",
    "        print(\"Some Error occured\")\n",
    "        print(\"File Name Maybe Wrong\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ques 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ques6():\n",
    "    import copy\n",
    "    from word2number import w2n \n",
    "\n",
    "    print(\"\\n Please Enter the File Name :\")\n",
    "    FileName=input()\n",
    "    try:\n",
    "\n",
    "        FilePointer = codecs.open(FileName, 'r', encoding = 'utf-8', errors = 'ignore')    \n",
    "        print(\"\\n Please enter the word you want to search :\")\n",
    "        word=input()\n",
    "        word=word.lower()\n",
    "        StemmedWord=stemmer(word)\n",
    "        # print(word,StemmedWord)\n",
    "        NumberFlag=0\n",
    "        try: \n",
    "            InputNumber=w2n.word_to_num(word)\n",
    "            print(\"Note : Input word represents the number :\"+ str(InputNumber) )\n",
    "            NumberFlag=1\n",
    "        except:\n",
    "            print(\"Note : Input word does not represent a number\")\n",
    "\n",
    "        MetadataList,SentencesList,MainText=get_sentences(FilePointer)\n",
    "        OrignalSentenceList=copy.deepcopy(SentencesList)\n",
    "        # SentencesList=remove_punctuations(SentencesList)\n",
    "        for i in range(len(SentencesList)):\n",
    "            SentencesList[i]=SentencesList[i].replace(\"\\n\",\" \")\n",
    "            SentencesList[i]=SentencesList[i].replace(\"\\t\",\" \")    \n",
    "            SentencesList[i]=SentencesList[i].lower()\n",
    "            SentencesList[i]=WordTokenize(SentencesList[i])\n",
    "\n",
    "        NumberOfSentences=0\n",
    "        NumberOfOccurence=0\n",
    "        SentenceFlag=0\n",
    "        Answer6List=[]\n",
    "        StemmedNumberOfSentences=0\n",
    "        StemmedNumberOfOccurence=0\n",
    "        StemmedSentenceFlag=0\n",
    "        StemmedAnswer6List=[]\n",
    "\n",
    "        for i in range(len(SentencesList)):\n",
    "            SentenceFlag=0\n",
    "            StemmedSentenceFlag=0\n",
    "            SplitSentence=remove_punctuations(SentencesList[i])\n",
    "            for index in range(len(SplitSentence)):\n",
    "                if(SplitSentence[index]==word or (NumberFlag==1 and SplitSentence[index]==str(InputNumber))):\n",
    "                    SentenceFlag=1\n",
    "                    NumberOfOccurence+=1\n",
    "                if(stemmer(SplitSentence[index])==StemmedWord or (NumberFlag==1 and SplitSentence[index]==str(InputNumber))):\n",
    "                    StemmedSentenceFlag=1\n",
    "                    StemmedNumberOfOccurence+=1\n",
    "            if(SentenceFlag==1):        \n",
    "                NumberOfSentences+=1\n",
    "                Answer6List.append(OrignalSentenceList[i])\n",
    "            if(StemmedSentenceFlag==1):\n",
    "                StemmedNumberOfSentences+=1\n",
    "                StemmedAnswer6List.append(OrignalSentenceList[i])\n",
    "\n",
    "        print(\"\\n****\\tOutput When Stemming was not used\\t***\\n\")        \n",
    "        print(\"\\n Number of occurence of input word :\"+str(NumberOfOccurence))\n",
    "        print(\"Number of sentence which contain input word :\"+str(NumberOfSentences))\n",
    "        if(NumberOfSentences>0):\n",
    "            print(\" The sentence are as follows:\\n\")\n",
    "            for i in range(len(Answer6List)):\n",
    "                print(\"\\n\"+str(i+1)+\":\",end=\" \")\n",
    "                print(Answer6List[i])\n",
    "\n",
    "#         print(\"\\n****\\tOutput when Applying porter stemmer on both input file in preproceesing and word\\t***\\n\")        \n",
    "#         print(\"\\n Number of occurence of input word(after stemming) :\"+str(StemmedNumberOfOccurence))\n",
    "#         print(\"Number of sentence which contain input word :\"+str(StemmedNumberOfSentences))\n",
    "#         if(StemmedNumberOfSentences>0):\n",
    "#             print(\" The sentence are as follows:\\n\")\n",
    "#             for i in range(len(StemmedAnswer6List)):\n",
    "#                 print(\"\\n\"+str(i+1)+\":\",end=\" \")\n",
    "#                 print(StemmedAnswer6List[i])\n",
    "    except:\n",
    "        print(\"Some Error occured\")\n",
    "        print(\"File Name Maybe Wrong\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ques7():\n",
    "    import copy\n",
    "    print(\"\\n Please Enter the File Name :\")\n",
    "    FileName=input()\n",
    "    try:\n",
    "        FilePointer = codecs.open(FileName, 'r', encoding = 'utf-8', errors = 'ignore')    \n",
    "        MetadataList,SentencesList,MainText=get_sentences(FilePointer)\n",
    "        \n",
    "        OrignalSentenceList=copy.deepcopy(SentencesList)\n",
    "        for i in range(len(SentencesList)):\n",
    "            SentencesList[i]=SentencesList[i].replace(\"\\n\",\" \")\n",
    "            SentencesList[i]=SentencesList[i].replace(\"\\t\",\" \")    \n",
    "            \n",
    "        table = str.maketrans('','', \"\\\"#$%&\\'()*+,-/:;<=>@[\\\\]^_`{|}~\")\n",
    "        NumberOfSentences=0\n",
    "        Answer7List=[]\n",
    "        # count=0\n",
    "        for i in range(len(SentencesList)):\n",
    "            SplitSentence=SentencesList[i].lower()\n",
    "            SplitSentence=WordTokenize(SplitSentence)\n",
    "            SplitSentence= [w.translate(table) for w in SplitSentence ]            \n",
    "            index=len(SplitSentence)-1\n",
    "            while(index>0 and SplitSentence[index]==\"\"):\n",
    "                index-=1\n",
    "            if(index<0):\n",
    "                continue\n",
    "        #     count+=1\n",
    "            if(SplitSentence[index]==\"?\"):\n",
    "                NumberOfSentences+=1\n",
    "                Answer7List.append(OrignalSentenceList[i])\n",
    "        # print(count,len(SentencesList))\n",
    "        print(\"\\n Number of questions in input file: \"+str(NumberOfSentences))\n",
    "        if(NumberOfSentences!=0):\n",
    "            print(\" The questions are as follows:\\n\")\n",
    "            for i in range(len(Answer7List)):\n",
    "                print(\"\\n\"+str(i+1)+\":\",end=\" \")\n",
    "                print(Answer7List[i])\n",
    "    except:\n",
    "        print(\"Some Error occured\")\n",
    "        print(\"File Name Maybe Wrong\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ques 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ques8():\n",
    "    import copy\n",
    "    print(\"\\n Please Enter the File Name :\")\n",
    "    FileName=input()\n",
    "    try:\n",
    "        FilePointer = codecs.open(FileName, 'r', encoding = 'utf-8', errors = 'ignore')    \n",
    "        MetadataList,SentencesList,MainText=get_sentences(FilePointer)\n",
    "        print(\"\\n The outputs are as follows:\")\n",
    "        for i in MetadataList:\n",
    "            TempTokenList=WordTokenize(i)\n",
    "            for token in TempTokenList:\n",
    "                if(re.match(\"^[0-2][0-9]:[0-6][0-9]:[0-6][0-9]$\",token)):\n",
    "                    time=token.split(\":\")\n",
    "                    hours=int(time[0])\n",
    "                    minutes=int(time[1])\n",
    "                    seconds=int(time[2])\n",
    "                    if(hours >=0 and hours<=23 and minutes >=0 and minutes<=59 and seconds >=0 and seconds <=59):                \n",
    "                        print(time[1] +\" Minutes \"+time[2] + \" seconds\")\n",
    "        TempTokenList=WordTokenize(MainText)\n",
    "        for token in TempTokenList:\n",
    "            if(re.match(\"^[0-2][0-9]:[0-6][0-9]:[0-6][0-9]$\",token)):\n",
    "                time=token.split(\":\")\n",
    "                hours=int(time[0])\n",
    "                minutes=int(time[1])\n",
    "                seconds=int(time[2])\n",
    "                if(hours >=0 and hours<=23 and minutes >=0 and minutes<=59 and seconds >=0 and seconds <=59):                \n",
    "                    print(time[1] +\" Minutes \"+time[2] + \" seconds\")\n",
    "    except:\n",
    "        print(\"Some Error occured\")\n",
    "        print(\"File Name Maybe Wrong\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ques 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ques9():\n",
    "    print(\"\\n Please Enter the File Name :\")\n",
    "    FileName=input()\n",
    "    try:\n",
    "        FilePointer = codecs.open(FileName, 'r', encoding = 'utf-8', errors = 'ignore')    \n",
    "        MetadataList,SentencesList,MainText=get_sentences(FilePointer)\n",
    "        TokensList=WordTokenize(MainText)\n",
    "        AbbList=[]\n",
    "        for i in TokensList:\n",
    "            if(re.match(\"^[A-Z][A-Z]*[A-Z]$\",i)):\n",
    "                AbbList.append(i)\n",
    "            elif(re.match(\"^[A-Z][a-zA-Z.]*\\.$\",i)):\n",
    "                AbbList.append(i)\n",
    "        if(len(AbbList)==0):\n",
    "            print(\"Could Not find any abbreviations\")\n",
    "        else:\n",
    "            print(\"The abbreviations are:\")\n",
    "            for i in AbbList:\n",
    "                print(i)\n",
    "    except:\n",
    "        print(\"Some Error occured\")\n",
    "        print(\"File Name Maybe Wrong\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter number from 1 to 9 for the corresponding question :\n",
      "1) Print the number of words and sentences contained in the file given as input.\n",
      "2) Print the number of words starting with consonants and vowels\n",
      "3) List all the email ids in the file given as input.\n",
      "4) Print the sentences and number of sentences starting with a given word in an input file.\n",
      "5) Print the sentences and number of sentences ending with a given word in an input file.\n",
      "6) Given a word and a file as input, print the count of that word and sentences containing that word in the input file.\n",
      "7) Given an input file, print the questions present, if any, in that file.\n",
      "8) List the minutes and seconds mentioned in the date present in the file given as input.\n",
      "9) List the abbreviations present in a file given as input.\n",
      "10) Exit\n",
      "\n",
      " Enter the task number :\n",
      "1\n",
      "\n",
      " Please Enter the File Name :\n",
      "58015\n",
      "Not a Valid file\n",
      "\n",
      " Enter the task number :\n",
      "1\n",
      "\n",
      " Please Enter the File Name :\n",
      "580125\n",
      "Not a Valid file\n",
      "\n",
      " Enter the task number :\n",
      "1\n",
      "\n",
      " Please Enter the File Name :\n",
      "103412\n",
      "Not a Valid file\n",
      "\n",
      " Enter the task number :\n",
      "1\n",
      "\n",
      " Please Enter the File Name :\n",
      "103241\n",
      "Not a Valid file\n",
      "\n",
      " Enter the task number :\n",
      "1\n",
      "\n",
      " Please Enter the File Name :\n",
      "103142\n",
      "Not a Valid file\n",
      "\n",
      " Enter the task number :\n",
      "1\n",
      "\n",
      " Please Enter the File Name :\n",
      "10\n",
      "Lines in Metadata:  12\n",
      "Number of sentences in text(without metadata):  17\n",
      "Number of words in text(without metadata):  289\n",
      "\n",
      " Enter the task number :\n",
      "2\n",
      "\n",
      " Please Enter the File Name :\n",
      "10\n",
      "Number of words starting with vowels :96\n",
      "Number of words starting with consonants :193\n",
      "\n",
      " Enter the task number :\n",
      "3\n",
      "\n",
      " Please Enter the File Name :\n",
      "10\n",
      "\n",
      " All the emails present in the document are:\n",
      "\n",
      "euclid@mrcnext.cso.uiuc.edu\n",
      "C51o24.8A4@news.cso.uiuc.edu\n",
      "1993Apr1.174424.3109@island.COM\n",
      "7837@blue.cis.pitt.edu\n",
      "C50MFo.5I2@news.cso.uiuc.edu\n",
      "7860@blue.cis.pitt.edu\n",
      "usenet@news.cso.uiuc.edu\n",
      "kxgst1+@pitt.edu\n",
      "kxgst1+@pitt.edu\n",
      "kxgst1+@pitt.edu\n",
      "\n",
      " All the unique emails present in the document are:\n",
      "\n",
      "7860@blue.cis.pitt.edu\n",
      "1993Apr1.174424.3109@island.COM\n",
      "C51o24.8A4@news.cso.uiuc.edu\n",
      "C50MFo.5I2@news.cso.uiuc.edu\n",
      "7837@blue.cis.pitt.edu\n",
      "usenet@news.cso.uiuc.edu\n",
      "kxgst1+@pitt.edu\n",
      "euclid@mrcnext.cso.uiuc.edu\n",
      "\n",
      " Enter the task number :\n",
      "4\n",
      "\n",
      " Please Enter the File Name :\n",
      "10\n",
      "\n",
      " Please enter the word you want to search :\n",
      "the\n",
      "Input word does not represent a number\n",
      "\n",
      " Number of sentences starting with the :0\n",
      "\n",
      " Enter the task number :\n",
      "4\n",
      "\n",
      " Please Enter the File Name :\n",
      "10\n",
      "\n",
      " Please enter the word you want to search :\n",
      "it\n",
      "Input word does not represent a number\n",
      "\n",
      " Number of sentences starting with it :0\n",
      "\n",
      " Enter the task number :\n",
      "4\n",
      "\n",
      " Please Enter the File Name :\n",
      "10\n",
      "\n",
      " Please enter the word you want to search :\n",
      "like\n",
      "Input word does not represent a number\n",
      "\n",
      " Number of sentences starting with like :1\n",
      " The sentence are as follows:\n",
      "\n",
      "\n",
      "1: Like Prozac, for instance; Prozac has been shown to be theraputic in\n",
      "some cases where the tri-cyclics fail.\n",
      "\n",
      " Enter the task number :\n",
      "5\n",
      "\n",
      " Please Enter the File Name :\n",
      "10\n",
      "\n",
      " Please enter the word you want to search :\n",
      "fail\n",
      "Input word does not represent a number\n",
      "\n",
      " Number of sentences starting with fail :1\n",
      " The sentence are as follows:\n",
      "\n",
      "\n",
      "1: Like Prozac, for instance; Prozac has been shown to be theraputic in\n",
      "some cases where the tri-cyclics fail.\n",
      "\n",
      " Enter the task number :\n",
      "6\n",
      "\n",
      " Please Enter the File Name :\n",
      "10\n",
      "\n",
      " Please enter the word you want to search :\n",
      "the\n",
      "Note : Input word does not represent a number\n",
      "\n",
      "****\tOutput When Stemming was not used\t***\n",
      "\n",
      "\n",
      " Number of occurence of input word :11\n",
      "Number of sentence which contain input word :6\n",
      " The sentence are as follows:\n",
      "\n",
      "\n",
      "1: Keep in mind however that those were\n",
      ">the days when a bottle of Coca Cola really did contain coca extract and\n",
      ">a certain amount of active cocaine.\n",
      "\n",
      "2: Taking\n",
      "anything as a drug for theraputic purposes implicitly carries the idea\n",
      "of taking a dose where the benefits are not exceeded by any unwanted,\n",
      "additional effects.\n",
      "\n",
      "3: Taking any drug when the potential ill-effects are\n",
      "not known is a risk assumed by the parties involved, and it may be that\n",
      "in a given situation the risk is worthwhile.\n",
      "\n",
      "4: Like Prozac, for instance; Prozac has been shown to be theraputic in\n",
      "some cases where the tri-cyclics fail.\n",
      "\n",
      "5: Should Prozac be taken off the market because\n",
      "long-term effects, if any, are not known?\n",
      "\n",
      "6: =\n",
      "--\n",
      "Euclid K.       standard disclaimers apply\n",
      "\"It is a bit ironic that we need the wave model [of light] to understand the\n",
      "propagation of light only through that part of the system where it leaves no\n",
      "trace.\"\n",
      "\n",
      " Enter the task number :\n",
      "7\n",
      "\n",
      " Please Enter the File Name :\n",
      "10\n",
      "\n",
      " Number of questions in input file: 1\n",
      " The questions are as follows:\n",
      "\n",
      "\n",
      "1: Should Prozac be taken off the market because\n",
      "long-term effects, if any, are not known?\n",
      "\n",
      " Enter the task number :\n",
      "8\n",
      "\n",
      " Please Enter the File Name :\n",
      "10\n",
      "\n",
      " The outputs are as follows:\n",
      "20 Minutes 27 seconds\n",
      "\n",
      " Enter the task number :\n",
      "9\n",
      "\n",
      " Please Enter the File Name :\n",
      "10\n",
      "The abbreviations are:\n",
      "IMHO\n",
      "PA\n",
      "PA\n",
      "K.\n",
      "\n",
      " Enter the task number :\n"
     ]
    }
   ],
   "source": [
    "print(\"Enter number from 1 to 9 for the corresponding question :\")\n",
    "print(\"1) Print the number of words and sentences contained in the file given as input.\")\n",
    "print(\"2) Print the number of words starting with consonants and vowels\")\n",
    "print(\"3) List all the email ids in the file given as input.\")\n",
    "print(\"4) Print the sentences and number of sentences starting with a given word in an input file.\")\n",
    "print(\"5) Print the sentences and number of sentences ending with a given word in an input file.\")\n",
    "print(\"6) Given a word and a file as input, print the count of that word and sentences containing that word in the input file.\")\n",
    "print(\"7) Given an input file, print the questions present, if any, in that file.\")\n",
    "print(\"8) List the minutes and seconds mentioned in the date present in the file given as input.\")\n",
    "print(\"9) List the abbreviations present in a file given as input.\")\n",
    "print(\"10) Exit\")\n",
    "Selection=11\n",
    "while(True):\n",
    "    print(\"\\n Enter the task number :\")\n",
    "    Selection=int(input())\n",
    "    if(Selection==1):\n",
    "        ques1()\n",
    "    elif(Selection==2):\n",
    "        ques2()\n",
    "    elif(Selection==3):\n",
    "        ques3()\n",
    "    elif(Selection==4):\n",
    "        ques4()\n",
    "    elif(Selection==5):\n",
    "        ques5()\n",
    "    elif(Selection==6):\n",
    "        ques6()\n",
    "    elif(Selection==7):\n",
    "        ques7()\n",
    "    elif(Selection==8):\n",
    "        ques8()\n",
    "    elif(Selection==9):\n",
    "        ques9()\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
