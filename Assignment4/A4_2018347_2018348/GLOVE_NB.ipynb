{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from scipy import spatial\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['laptop', 'netbook', 'from', 'bought', 'machine']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GLOVE for english.txt\n",
    "glove_vectors_eng = pd.read_csv(\"./files/eng-glove-vectors3.txt\", sep=' ', header=None)\n",
    "# glove_vectors_eng = pd.read_csv(\"./files/eng-glove-vectors5.txt\", sep=' ', header=None)\n",
    "vocab=glove_vectors_eng[0].astype('str') # vocab contains list of vocabulary\n",
    "glove_vectors_eng_dic={} # this is the dict of glove vector and word mapping\n",
    "for i in range(len(vocab)):\n",
    "    glove_vectors_eng_dic[vocab[i]]=np.array((glove_vectors_eng.iloc[i,1:].astype('float64')))\n",
    "def find_closest_glove_eng(input_word,n=5):\n",
    "    if input_word not in glove_vectors_eng_dic:\n",
    "        return []\n",
    "    embedding=glove_vectors_eng_dic[input_word]\n",
    "    return sorted(glove_vectors_eng_dic.keys(), key=lambda word: spatial.distance.euclidean(glove_vectors_eng_dic[word], embedding))[1:n+1]\n",
    "eng_vocab=list(glove_vectors_eng_dic.keys())\n",
    "# eng_vocab\n",
    "find_closest_glove_eng('computer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['अवसर', 'विहंगम', 'ब्लुटूथ', 'रास्ता', 'झील']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GLOVE for hindi.txt\n",
    "glove_vectors_hindi= pd.read_csv(\"./files/hindi-glove-vectors.txt\", sep=' ', header=None)\n",
    "# glove_vectors_hindi= pd.read_csv(\"./files/hindi-glove-vectors3.txt\", sep=' ', header=None)\n",
    "vocab=glove_vectors_hindi[0].astype('str') # vocab contains list of vocabulary\n",
    "# vocab\n",
    "glove_vectors_hindi_dic={} # this is the dict of glove vector and word mapping\n",
    "for i in range(len(vocab)):\n",
    "    glove_vectors_hindi_dic[vocab[i]]=np.array((glove_vectors_hindi.iloc[i,1:].astype('float64')))\n",
    "def find_closest_glove_hindi(input_word,n=5):\n",
    "    if input_word not in glove_vectors_hindi_dic:\n",
    "        return []\n",
    "    embedding=glove_vectors_hindi_dic[input_word]\n",
    "    return sorted(glove_vectors_hindi_dic.keys(), key=lambda word: spatial.distance.euclidean(glove_vectors_hindi_dic[word], embedding))[1:n+1]\n",
    "hindi_vocab=list(glove_vectors_hindi_dic.keys())\n",
    "find_closest_glove_hindi('लाभ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bing_liu=pd.read_csv(\"./files/BingLiu.csv\",names=[\"word\",\"polarity\"],delimiter=\"\\t\")\n",
    "dictionary=open(\"./files/english-hindi-dictionary.txt\",'rb')\n",
    "string=dictionary.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_list=[]\n",
    "for i in string:\n",
    "    dictionary_list.append(i.decode('utf-8').replace(\"\\n\",\"\").split(\"|||\"))\n",
    "dictionary_list\n",
    "dic_eng_hindi={}\n",
    "dic_hindi_eng={}\n",
    "\n",
    "# interferece becomes dakhal andazai\n",
    "# need someway to handle this\n",
    "\n",
    "for i in dictionary_list:\n",
    "    if(i[0].replace(\" \",\"\")!=i[1].replace(\" \",\"\")):\n",
    "        if(i[0][:-1] in dic_eng_hindi):\n",
    "            dic_eng_hindi[i[0][:-1]].append(i[1][1:])\n",
    "        else:\n",
    "            dic_eng_hindi[i[0][:-1]]=[i[1][1:]]\n",
    "        if(i[1][1:] in dic_hindi_eng):\n",
    "            dic_hindi_eng[i[1][1:]].append(i[0][:-1])\n",
    "        else:\n",
    "            dic_hindi_eng[i[1][1:]]=[i[0][:-1]]\n",
    "# print(dic_eng_hindi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "billingual_lexicon=[]\n",
    "for i in range(len(bing_liu['word'])):\n",
    "#     print(i)\n",
    "    if(bing_liu['word'][i] in dic_eng_hindi):\n",
    "        temp_eng=bing_liu['word'][i]\n",
    "        for j in dic_eng_hindi[temp_eng]:\n",
    "            billingual_lexicon.append([temp_eng,j,bing_liu['polarity'][i]])\n",
    "# for i in billingual_lexicon:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_biLex=set()\n",
    "for i in billingual_lexicon:\n",
    "    set_biLex.add((i[0],i[1],i[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extended Lexicons for closest 5 words:\n",
      "('simple', 'सरल', 'positive')\n",
      "('disappointed', 'निराश', 'positive')\n",
      "('impressed', 'प्रभावित', 'negative')\n"
     ]
    }
   ],
   "source": [
    "Old_List=billingual_lexicon\n",
    "count=0\n",
    "print(\"Extended Lexicons for closest 5 words:\")\n",
    "while (len(Old_List)!=0):\n",
    "    entry=Old_List[0]\n",
    "    Old_List.pop(0)\n",
    "    e_word=entry[0]\n",
    "    h_word=entry[1]\n",
    "    eng_5_close_words=find_closest_glove_eng(e_word,5)\n",
    "    hin_5_close_words=find_closest_glove_hindi(h_word,5)\n",
    "    if(len(eng_5_close_words)==0) or (len(hin_5_close_words)==0):\n",
    "        count+=1\n",
    "        continue\n",
    "    for i in eng_5_close_words:\n",
    "        if(i in dic_eng_hindi):\n",
    "            for j in hin_5_close_words:\n",
    "                 if j in dic_eng_hindi[i]:\n",
    "                        temp=[i,j,entry[2]]\n",
    "                        temp2=(i,j,entry[2])\n",
    "                        if temp2 not in set_biLex:\n",
    "#                             print(entry)\n",
    "#                             print(i,j)\n",
    "                            billingual_lexicon.append(temp)\n",
    "                            Old_List.append(temp)\n",
    "                            print(temp2)\n",
    "                            set_biLex.add(temp2)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
